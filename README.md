# ðŸ“– Arquitetura e DecisÃµes TÃ©cnicas: Nola God Level Challenge

Este documento descreve as tecnologias, a arquitetura e as funcionalidades implementadas neste projeto, que visa resolver o problema de anÃ¡lise de dados para donos de restaurantes.

## 1. Tecnologias Utilizadas

O projeto Ã© dividido em dois ecossistemas principais: o ambiente de dados (Docker/Python) e a aplicaÃ§Ã£o web (Next.js/Prisma).

### AplicaÃ§Ã£o Principal (Monorepo `apps/frontend`)

* **Framework Full-stack:** [Next.js](https://nextjs.org/) (com React 19)
* **Linguagem:** [TypeScript](https://www.typescriptlang.org/)
* **Banco de Dados (ORM):** [Prisma](https://www.prisma.io/) (conectado ao Postgres)
* **Data Fetching (Client-side):** [SWR](https://swr.vercel.app/) (para caching e revalidaÃ§Ã£o de dados em tempo real)
* **UI (Componentes):** [shadcn/ui](https://ui.shadcn.com/) (construÃ­do sobre Radix UI e Tailwind CSS)
* **VisualizaÃ§Ã£o de Dados:** [Recharts](https://recharts.org/) (para grÃ¡ficos dinÃ¢micos)
* **EstilizaÃ§Ã£o:** [Tailwind CSS](https://tailwindcss.com/)
* **ValidaÃ§Ã£o de Schema:** [Zod](https://zod.dev/) (usado nas rotas de API)
* **Ãcones:** [Lucide React](https://lucide.dev/)

### Ambiente de Dados e GeraÃ§Ã£o

* **ContainerizaÃ§Ã£o:** [Docker](https://www.docker.com/) e [Docker Compose](https://docs.docker.com/compose/)
* **Banco de Dados:** [PostgreSQL 15](https://www.postgresql.org/)
* **Scripting de Dados:** [Python 3.11](https://www.python.org/)
* **Bibliotecas Python:** `psycopg2-binary` (para conectar ao Postgres) e `Faker` (para geraÃ§Ã£o de dados massivos)

---

## 2. DecisÃµes TÃ©cnicas e Arquitetura

1.  **Monorepo com NPM Workspaces:**
    O projeto estÃ¡ estruturado como um monorepo gerenciado pelo `npm workspaces`. A aplicaÃ§Ã£o (`apps/frontend`) Ã© mantida em um workspace, permitindo o compartilhamento de configuraÃ§Ãµes e facilitando a instalaÃ§Ã£o de dependÃªncias com um Ãºnico `npm install` na raiz.

2.  **Arquitetura "Backend-for-Frontend" (BFF):**
    A aplicaÃ§Ã£o Next.js atua como um sistema full-stack. O frontend (React Server Components e Client Components em `app/page.tsx`) consome dados de suas prÃ³prias rotas de API (`app/api/*`). Essas rotas de API, por sua vez, usam o Prisma para se comunicar com o banco de dados. Isso simplifica a arquitetura, elimina a necessidade de um servidor backend separado e melhora a seguranÃ§a (nenhuma credencial de banco Ã© exposta ao cliente).

3.  **GeraÃ§Ã£o DinÃ¢mica de SQL (O CoraÃ§Ã£o do Desafio):**
    Para atender ao requisito principal de "analytics customizÃ¡vel", a decisÃ£o foi **nÃ£o** usar o ORM para queries complexas. Em vez disso, o `query-builder-helpers.ts` constrÃ³i dinamicamente strings de SQL `raw` (SQL puro) com base nas mÃ©tricas e dimensÃµes selecionadas pelo usuÃ¡rio no `QueryBuilder`. Essas queries sÃ£o executadas com seguranÃ§a usando `prisma.$queryRawUnsafe`, o que oferece performance mÃ¡xima e flexibilidade total de queries, algo que seria difÃ­cil ou impossÃ­vel de alcanÃ§ar com o ORM puro.

4.  **Data Fetching Otimizado com SWR:**
    O frontend utiliza `useSWR` para buscar dados das rotas de API. Isso oferece uma excelente experiÃªncia ao usuÃ¡rio, pois os dados sÃ£o cacheados e revalidados automaticamente, o que torna a navegaÃ§Ã£o entre filtros e focos de anÃ¡lise quase instantÃ¢nea apÃ³s o primeiro carregamento.

5.  **Ambiente de Dados ReprodutÃ­vel com Docker:**
    O banco de dados e a geraÃ§Ã£o de dados sÃ£o totalmente containerizados. O `docker-compose.yml` orquestra:
    * Um serviÃ§o `postgres` que usa o schema de `database-schema.sql`.
    * Um serviÃ§o `data-generator` que aguarda o banco ficar pronto e, em seguida, executa o `generate_data.py` para popular 500k+ de vendas realistas, simulando o ambiente do desafio.

6.  **Prisma Accelerate:**
    O projeto estÃ¡ configurado para usar o `Prisma Accelerate`, uma decisÃ£o que visa a performance em produÃ§Ã£o. Ele fornece um pool de conexÃµes de banco de dados gerenciado, o que Ã© crucial em ambientes Serverless (como a Vercel, onde as rotas de API do Next.js sÃ£o executadas) para evitar a exaustÃ£o de conexÃµes do banco.

---

## 3. Funcionalidades (Features) Implementadas

A plataforma permite que o usuÃ¡rio (como a "Maria", dona do restaurante) explore seus dados de forma intuitiva.

* **Dashboard Principal (`page.tsx`)**:
    * **KPIs Principais:** Exibe os cartÃµes de "Faturamento Total", "Ticket MÃ©dio" e "Total de Pedidos" com indicadores de tendÃªncia (alta ou baixa) em comparaÃ§Ã£o com o perÃ­odo anterior.
    * **Insights AutomÃ¡ticos:** Analisa os dados e apresenta insights acionÃ¡veis em linguagem natural, como "Faturamento em alta" ou "Canal X precisa de atenÃ§Ã£o".

* **Filtros Globais e Contextuais (`SecondaryFilters`)**:
    * Permite ao usuÃ¡rio filtrar todos os dados do dashboard por **PerÃ­odo** (Hoje, Ãšltimos 7 dias, etc.).
    * Filtros contextuais de **Loja** (multi-seleÃ§Ã£o), **Canal** e **Produto** aparecem dependendo do foco da anÃ¡lise.

* **Foco de AnÃ¡lise (`AnalysisFocusSidebar`)**:
    Permite ao usuÃ¡rio mudar o contexto do dashboard para se aprofundar em Ã¡reas especÃ­ficas:
    * **VisÃ£o Geral:** Panorama do negÃ³cio com evoluÃ§Ã£o de faturamento e divisÃ£o por canal/loja.
    * **Lojas:** Compara a performance entre lojas e mostra os top produtos da(s) loja(s) selecionada(s).
    * **Produtos:** Exibe um ranking detalhado dos produtos mais vendidos.
    * **Canais de Venda:** Foca na performance de Delivery vs. Presencial.
    * **AnÃ¡lise Temporal:** Mostra padrÃµes de vendas por hora do dia e dia da semana.
    * **Clientes:** (Estrutura pronta para anÃ¡lise de comportamento de clientes).

* **Construtor de VisualizaÃ§Ãµes (`QueryBuilder`)**:
    * **Feature Core:** Esta Ã© a funcionalidade principal que resolve o desafio.
    * Permite que o usuÃ¡rio **crie seu prÃ³prio grÃ¡fico** selecionando:
        1.  **Uma MÃ©trica:** (O que medir? Ex: Faturamento, Pedidos, Ticket MÃ©dio).
        2.  **Uma DimensÃ£o:** (Como agrupar? Ex: Por Loja, Por Dia da Semana, Por Produto).
        3.  **Um Tipo de GrÃ¡fico:** (Barras, Linha ou Pizza).
    * Ao clicar em "Gerar VisualizaÃ§Ã£o", o frontend envia essa configuraÃ§Ã£o para a API (`/api/query`), que constrÃ³i a query SQL dinamicamente e retorna os dados para o `DynamicChart`.
---

## 4. Fluxo de Dados (Exemplo: AnÃ¡lise Customizada)

Para ilustrar como as partes se conectam, este Ã© o fluxo de dados quando um usuÃ¡rio cria uma visualizaÃ§Ã£o personalizada:

1.  **UI (Frontend):** O usuÃ¡rio seleciona "Ticket MÃ©dio" (mÃ©trica) e "Por Dia da Semana" (dimensÃ£o) no componente `QueryBuilder` e clica em "Gerar VisualizaÃ§Ã£o".
2.  **Estado (Frontend):** O `page.tsx` captura essa mudanÃ§a e atualiza seu estado `customQuery`. Esta mudanÃ§a de estado faz com que o hook `useSWR` recalcule a URL da API.
3.  **Fetch (Frontend):** O SWR usa o `fetcher` para fazer uma requisiÃ§Ã£o GET para a URL construÃ­da, algo como: `/api/query?metric=ticket&dimension=weekday&startDate=...`
4.  **API Route (Backend):** O endpoint `/api/query/route.ts` recebe a requisiÃ§Ã£o.
5.  **ValidaÃ§Ã£o (Backend):** Os parÃ¢metros (`metric`, `dimension`, etc.) sÃ£o validados usando Zod para garantir que sÃ£o valores esperados.
6.  **SQL Builder (Backend):** O `query-builder-helpers.ts` Ã© chamado. Ele mapeia "ticket" para `AVG(s.total_amount)` e "weekday" para `EXTRACT(ISODOW FROM s.created_at)`, construindo dinamicamente uma query SQL raw.
7.  **Banco de Dados (Backend):** A API executa a query SQL pura no PostgreSQL usando `prisma.$queryRawUnsafe`.
8.  **SerializaÃ§Ã£o (Backend):** A resposta do banco (que pode incluir tipos `Decimal` ou `BigInt`) Ã© serializada para um JSON seguro usando `serializePrismaData`.
9.  **Resposta (Frontend):** O JSON Ã© retornado ao SWR, que o disponibiliza para o componente `DynamicChart`, renderizando o grÃ¡fico de ticket mÃ©dio por dia da semana para o usuÃ¡rio.

## 5. Estrutura da API (Endpoints)

A aplicaÃ§Ã£o expÃµe um conjunto de endpoints de API para alimentar o dashboard:

* **`/api/kpis`**: Retorna os KPIs principais (Faturamento, Pedidos, Ticket MÃ©dio, Descontos, Cancelados) para o perÃ­odo filtrado.
* **`/api/filters`**: Retorna as listas de Lojas, Canais e Produtos disponÃ­veis para popular os menus de filtro.
* **`/api/sales-timeseries`**: Retorna dados de receita agregados por dia, semana ou mÃªs, usado no grÃ¡fico de "EvoluÃ§Ã£o do Faturamento".
* **`/api/ranking/products`**: Fornece uma lista dos produtos mais vendidos, ordenados por receita ou quantidade.
* **`/api/distribution/channel`**: Retorna a receita e o nÃºmero de vendas agrupados por canal (iFood, Rappi, etc.).
* **`/api/meta/last-date`**: Um endpoint de metadados que retorna a data da Ãºltima venda registrada no banco. Isso Ã© usado para ajustar dinamicamente o filtro de perÃ­odo, garantindo que o usuÃ¡rio nÃ£o analise dias futuros sem dados.
* **`/api/query`**: O endpoint principal para o `QueryBuilder`. Ele Ã© flexÃ­vel e constrÃ³i a query SQL com base nos parÃ¢metros `metric` e `dimension` recebidos.

## 6. Resolvendo as "Dores da Maria" (PROBLEMA.md)

O design da soluÃ§Ã£o foi focado em resolver diretamente as perguntas de negÃ³cio listadas no `PROBLEMA.md`.

* **"Qual produto vende mais na quinta Ã  noite no iFood?"**
    * **SoluÃ§Ã£o:** O `QueryBuilder` (MÃ©trica: Quantidade, DimensÃ£o: Produto) + Foco de AnÃ¡lise Temporal (DimensÃ£o: Hora do Dia e Dia da Semana) + Filtro de Canal (iFood). O usuÃ¡rio pode cruzar essas informaÃ§Ãµes para obter a resposta.

* **"Meu ticket mÃ©dio estÃ¡ caindo. Ã‰ por canal ou por loja?"**
    * **SoluÃ§Ã£o:** O `QueryBuilder`.
        1.  MÃ©trica: `Ticket MÃ©dio`, DimensÃ£o: `Por Canal`.
        2.  MÃ©trica: `Ticket MÃ©dio`, DimensÃ£o: `Por Loja`.
    * A comparaÃ§Ã£o com o perÃ­odo anterior nos KPIs e os Insights AutomÃ¡ticos ajudam a identificar essa queda automaticamente.

* **"Meu tempo de entrega piorou. Em quais dias/horÃ¡rios?"**
    * **SoluÃ§Ã£o:** O `QueryBuilder`. MÃ©trica: `Tempo de Entrega`, DimensÃ£o: `Por Dia da Semana` ou `Por Hora do Dia`.

* **"Quais clientes compraram 3+ vezes...?"**
    * **SoluÃ§Ã£o:** Embora o frontend nÃ£o tenha um relatÃ³rio especÃ­fico para *esta* pergunta, o schema do banco (`customers` e `sales`) suporta essa anÃ¡lise. O Foco de AnÃ¡lise "Clientes" Ã© o local designado para esta funcionalidade futura.

* **"Quais produtos tÃªm menor margem...?"**
    * **SoluÃ§Ã£o:** Similar ao anterior. O schema `products` nÃ£o inclui `custo`, entÃ£o a *margem* nÃ£o pode ser calculada. No entanto, a anÃ¡lise de "Top Produtos" por receita e volume Ã© o primeiro passo para essa anÃ¡lise.

## 7. Pontos de Melhoria e PrÃ³ximos Passos

* **Custo e Margem:** Adicionar um campo `cost` (custo) na tabela `products` permitiria o cÃ¡lculo de margem, habilitando mÃ©tricas financeiras mais profundas.
* **AnÃ¡lise de Clientes (RFV):** Implementar a seÃ§Ã£o "Clientes" com anÃ¡lises de RecÃªncia, FrequÃªncia e Valor (RFV).
* **Cache de Queries:** As queries `raw` mais pesadas (especialmente do `QueryBuilder`) poderiam ser cacheadas na camada de API (ex: com Redis) ou no prÃ³prio banco usando Views Materializadas, em vez de depender apenas do cache do SWR no cliente.
* **Testes:** Adicionar testes unitÃ¡rios para o `query-builder-helpers.ts` e testes de integraÃ§Ã£o para os endpoints da API seria crucial para a estabilidade.

# ðŸš€ Como Rodar o Projeto

Existem duas formas de rodar este projeto: um script automatizado (recomendado) ou um
passo a passo manual.

## PrÃ©-requisitos

Antes de comeÃ§ar, garanta que vocÃª tenha as seguintes ferramentas instaladas em sua
mÃ¡quina:

```
â— Git
â— Docker e Docker Compose
â— Node.js (v18 ou superior)
â— npm (geralmente instalado com o Node.js)
```
## OpÃ§Ã£o 1: Script Automatizado (Recomendado)

Este mÃ©todo irÃ¡ configurar o banco de dados, popular os dados, instalar as dependÃªncias do frontend e iniciar o servidor de desenvolvimento com um Ãºnico comando.

1. **Clone o repositÃ³rio:**
```
    git clone https://github.com/vitor0ferreira/nola-god-level-challenge.git
    cd nola-god-level-challenge/nola-god-level-challenge-main
```
2. Crie o script startup.sh:
    Crie um arquivo chamado startup.sh na raiz do projeto (em nola-god-level-challenge-main/) e cole o seguinte conteÃºdo nele:
```
    #!/bin/bash
    # Script para configurar e iniciar o ambiente completo do Nola God Level Challenge.

# Para o script se um comando falhar
set -e

echo "--- 1. Parando e removendo containers antigos do projeto (se existirem)..."
docker compose down -v --remove-orphans

echo "--- 2. Construindo o container do gerador de dados..."
docker compose build --no-cache data-generator

echo "--- 3. Iniciando o banco de dados PostgreSQL em background..."
docker compose up -d postgres

echo "--- 4. Aguardando o banco de dados (godlevel-db) ficar pronto..."
# Espera atÃ© que o health check do 'postgres' no docker-compose.yml passe
until [ "$(docker inspect -f {{.State.Health.Status}} godlevel-db 2>/dev/null)" == "healthy"
]; do
echo -n "."
sleep 2
done
echo "\nBanco de dados estÃ¡ pronto!"

echo "--- 5. Gerando os dados... (Isso pode levar de 5 a 15 minutos)"
docker compose run --rm data-generator

echo "--- 6. Instalando dependÃªncias do projeto (root e workspace frontend)..."
npm install

echo "--- 7. Criando arquivo .env para o frontend em apps/frontend/.env..."
# O docker-compose.yml expÃµe a porta 5432 para o localhost
echo
"DATABASE_URL=postgresql://challenge:challenge_2024@localhost:5432/challenge_db"
> apps/frontend/.env
echo "Arquivo .env criado."

echo "--- 8. Gerando o Prisma Client para o frontend..."
npx prisma generate --schema=./apps/frontend/prisma/schema.prisma

echo "--- 9. Iniciando o servidor de desenvolvimento do frontend (Next.js)..."
echo "---"
echo "--- âœ… Ambiente pronto! ---"
echo "--- Acesse o dashboard em: http://localhost:3000 ---"
echo "---"

npm run dev
```
3. **DÃª permissÃ£o de execuÃ§Ã£o ao script:**
```
    chmod +x startup.sh
```
4. **Execute o script:**
```
    ./startup.sh
```

Ao final do processo, o script iniciarÃ¡ o servidor do frontend. Basta acessar **[http://localhost:3000](http://localhost:3000)** no seu navegador.


## OpÃ§Ã£o 2: Passo a Passo Manual

Se preferir fazer a instalaÃ§Ã£o manualmente, siga estas etapas:

1. **Clone o repositÃ³rio:**
```
    git clone
    [https://github.com/vitor0ferreira/nola-god-level-challenge.git](https://github.com/vitor0f
    erreira/nola-god-level-challenge.git)
    cd nola-god-level-challenge/nola-god-level-challenge-main
```
2. Inicie o Banco de Dados:
    Abra um terminal e rode o docker-compose para iniciar o Postgres. O healthcheck
    garantirÃ¡ que ele esteja pronto.
```
    docker compose up -d postgres
```

Aguarde cerca de 30 segundos atÃ© o banco de dados estar totalmente operacional.

3. Gere os Dados:
    Em outro terminal, execute o serviÃ§o data-generator para popular o banco.
    (Este passo pode levar de 5 a 15 minutos).
```
    docker compose run --rm data-generator
```
4. Instale as DependÃªncias do Frontend:
    Este comando instalarÃ¡ as dependÃªncias da raiz e do workspace apps/frontend.
```
    npm install
```
5. Crie o Arquivo de Ambiente (.env):
    O frontend (Prisma) precisa saber como se conectar ao banco de dados que estÃ¡
    rodando no Docker.
```
    echo
    "DATABASE_URL=postgresql://challenge:challenge_2024@localhost:5432/challenge_db"
    > apps/frontend/.env
```
6. Gere o Prisma Client:
    Este comando lÃª o schema.prisma e gera o cliente de banco de dados tipado.
```
    npx prisma generate --schema=./apps/frontend/prisma/schema.prisma
```
7. **Inicie o Servidor do Frontend:**
```
    npm run dev
```
8. Acesse o Dashboard:
    Abra seu navegador e acesse [http://localhost:3000.](http://localhost:3000.)

